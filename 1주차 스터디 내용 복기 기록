# [Week 01] Text Preprocessing for NLP & Language Models, Basic Model & Vectorization

### 📅 스터디 일시
- 2026년 1월 29일(목) 16:00~18:00

### 📅 스터디 주제
- **NLP를 위한 텍스트 전처리 및 언어 모델 기초**
- **기본 모델 및 벡터화(Vectorization) 기법**

### 🎯 학습 목표
1. 자연어 처리의 첫 단계인 데이터 정제와 토큰화 과정 이해
2. 텍스트 데이터를 컴퓨터가 이해할 수 있는 수치(Vector)로 변환하는 원리 학습

### 📝 주요 학습 내용
#### 1. Text Preprocessing (텍스트 전처리)
- **Tokenization:** 주어진 코퍼스에서 토큰이라 불리는 단위로 나누는 작업 (단어, 형태소 등)
- **Cleaning & Normalization:** 노이즈 데이터 제거 및 동일한 의미의 단어 통합 (어간 추출, 표제어 추출 등)
- **Stopwords:** 분석에 큰 의미가 없는 불용어 제거 과정

#### 2. Vectorization (벡터화)
- **Bag of Words (BoW):** 단어의 출현 빈도에 기반한 수치화 방식
- **TF-IDF:** 단어의 빈도와 역문서 빈도를 사용하여 단어의 중요도를 가중치로 표현하는 기법
- **One-hot Encoding:** 단어 집합의 크기를 벡터의 차원으로 하여 표현하는 기초적인 방식

#### 3. Language Model (언어 모델) 기초
- 단어 시퀀스에 확률을 할당하여 다음에 올 단어를 예측하는 모델의 기본 개념 이해

### 💡 느낀 점
- 텍스트 필터링 기술은 웹 방화벽에서 악성 스크립트 탐지하는 원리와 비슷해 보임.
- NLP 기술이 악성 페이로드 탐지 정확도를 높이는 데 핵심적일 수 있음을 배움.
